# SAM 2 ç®—æ³•åŸç†è¯¦è§£

## ğŸ¯ æ ¸å¿ƒä»»åŠ¡å®šä¹‰

### Promptable Visual Segmentation (PVS)

```python
class PromptableVisualSegmentation:
    def __init__(self):
        self.supports = ['points', 'boxes', 'masks']
        self.domain = 'images_and_videos'
    
    def process_prompt(self, video_frames, prompts):
        """
        è¾“å…¥: 
        - video_frames: è§†é¢‘å¸§åºåˆ— [T, H, W, 3]
        - prompts: åœ¨ä»»æ„å¸§ä¸Šçš„æç¤º {(frame_idx, prompt_type, prompt_data)}
        
        è¾“å‡º:
        - masklet: æ•´ä¸ªè§†é¢‘ä¸­çš„æ—¶ç©ºæ©ç åºåˆ— [T, H, W]
        """
        # å®æ—¶å“åº”è¢«æç¤ºå¸§
        # ä¼ æ’­åˆ°æ•´ä¸ªè§†é¢‘
        # æ”¯æŒè¿­ä»£ç»†åŒ–
```

**ä»»åŠ¡ç‰¹æ€§**ï¼š
- **è·¨å¸§äº¤äº’**ï¼šæç¤ºå¯å‡ºç°åœ¨ä»»æ„å¸§ï¼Œä¸é™äºç¬¬ä¸€å¸§
- **å®æ—¶åé¦ˆ**ï¼šåœ¨è¢«æç¤ºå¸§ç«‹å³ç”Ÿæˆæ©ç 
- **æ—¶ç©ºä¸€è‡´æ€§**ï¼šåœ¨æ•´ä¸ªè§†é¢‘ä¸­ä¿æŒåˆ†å‰²ä¸€è‡´æ€§
- **å¤šè½®ç»†åŒ–**ï¼šæ”¯æŒé€šè¿‡é¢å¤–æç¤ºä¿®æ­£åˆ†å‰²ç»“æœ

---

## ğŸ—ï¸ æ¨¡å‹æ¶æ„è¯¦è§£

### æ•´ä½“æ¶æ„æ¦‚è§ˆ

```
SAM 2 Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Image Encoder  â”‚ -> â”‚ Memory Attention  â”‚ -> â”‚  Mask Decoder   â”‚
â”‚   (Hiera)       â”‚    â”‚   (Transformer)   â”‚    â”‚  (Two-Way)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Multi-scale    â”‚    â”‚   Memory Bank    â”‚    â”‚  Object Pointer â”‚
â”‚   Features      â”‚    â”‚ (FIFO Queues)    â”‚    â”‚   Vectors       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. å›¾åƒç¼–ç å™¨ (Image Encoder)

```python
class HieraImageEncoder(nn.Module):
    def __init__(self, model_size='B+'):
        super().__init__()
        # åŸºäºMAEé¢„è®­ç»ƒçš„Hieraæ¶æ„
        self.backbone = HieraBackbone(model_size)
        self.fpn = FeaturePyramidNetwork()
        
    def forward(self, frame):
        # æå–å¤šå°ºåº¦ç‰¹å¾
        features = self.backbone(frame)  # [stride4, stride8, stride16, stride32]
        fused_features = self.fpn(features[stride16], features[stride32])
        return fused_features  # ç”¨äºè®°å¿†æ³¨æ„åŠ›
```

**å…³é”®æŠ€æœ¯ç‚¹**ï¼š
- **åˆ†å±‚ç‰¹å¾æå–**ï¼šstride 16å’Œ32ç‰¹å¾èåˆç”¨äºè®°å¿†æ³¨æ„åŠ›
- **å¤šå°ºåº¦è¿æ¥**ï¼šstride 4å’Œ8ç‰¹å¾ç›´æ¥è¿æ¥åˆ°æ©ç è§£ç å™¨ï¼ˆç»•è¿‡è®°å¿†ï¼‰
- **ä½ç½®ç¼–ç **ï¼šä½¿ç”¨çª—å£åŒ–ç»å¯¹ä½ç½®ç¼–ç ï¼Œç§»é™¤ç›¸å¯¹ä½ç½®åç½®(RPB)

### 2. è®°å¿†æ³¨æ„åŠ›æœºåˆ¶ (Memory Attention)

```python
class MemoryAttention(nn.Module):
    def __init__(self, L=4, dim=256):
        super().__init__()
        self.layers = nn.ModuleList([
            MemoryAttentionBlock(dim) for _ in range(L)
        ])
        
    def forward(self, current_frame_emb, memory_bank):
        """
        current_frame_emb: å½“å‰å¸§ç‰¹å¾ [B, H, W, C]
        memory_bank: è®°å¿†åº“åŒ…å«:
            - spatial_memories: æœ€è¿‘Nå¸§ç©ºé—´ç‰¹å¾
            - prompted_memories: æç¤ºå¸§è®°å¿†  
            - object_pointers: ç‰©ä½“æŒ‡é’ˆå‘é‡
        """
        x = current_frame_emb
        for layer in self.layers:
            # è‡ªæ³¨æ„åŠ› + è®°å¿†äº¤å‰æ³¨æ„åŠ› + MLP
            x = layer(x, memory_bank)
        return x
```

**è®°å¿†åº“è®¾è®¡**ï¼š
```python
class MemoryBank:
    def __init__(self, N=6, M=10):
        self.recent_frames = deque(maxlen=N)    # æœ€è¿‘å¸§è®°å¿†(FIFO)
        self.prompted_frames = deque(maxlen=M)  # æç¤ºå¸§è®°å¿†(FIFO)
        self.object_pointers = []               # ç‰©ä½“è¯­ä¹‰å‘é‡
        
    def add_memory(self, frame_emb, mask_pred, is_prompted=False):
        memory = self.memory_encoder(frame_emb, mask_pred)
        if is_prompted:
            self.prompted_frames.append(memory)
        else:
            self.recent_frames.append(memory)
        
        # æ›´æ–°ç‰©ä½“æŒ‡é’ˆ
        obj_ptr = self.extract_object_pointer(mask_pred)
        self.object_pointers.append(obj_ptr)
```

### 3. æ©ç è§£ç å™¨æ”¹è¿› (Enhanced Mask Decoder)

```python
class SAM2MaskDecoder(nn.Module):
    def __init__(self):
        super().__init__()
        # ç»§æ‰¿SAMçš„åŒå‘Transformerè®¾è®¡
        self.two_way_transformer = TwoWayTransformer()
        
        # æ–°å¢ç»„ä»¶
        self.occlusion_head = nn.Linear(dim, 1)  # é®æŒ¡é¢„æµ‹
        self.high_res_skip = HighResolutionSkip() # é«˜åˆ†è¾¨ç‡è·³è·ƒè¿æ¥
        
    def forward(self, conditioned_emb, prompts, image_features):
        # å¤„ç†æç¤º
        prompt_emb = self.prompt_encoder(prompts)
        
        # åŒå‘æ³¨æ„åŠ›æ›´æ–°
        mask_tokens, image_emb = self.two_way_transformer(
            prompt_emb, conditioned_emb
        )
        
        # å¤šæ©ç é¢„æµ‹å¤„ç†æ­§ä¹‰
        multi_masks = self.predict_multiple_masks(mask_tokens, image_emb)
        
        # é®æŒ¡é¢„æµ‹
        occlusion_score = self.occlusion_head(mask_tokens)
        
        # é«˜åˆ†è¾¨ç‡ä¸Šé‡‡æ ·ï¼ˆä½¿ç”¨stride4/8ç‰¹å¾ï¼‰
        upsampled_masks = self.high_res_skip(multi_masks, image_features)
        
        return upsampled_masks, occlusion_score, mask_tokens
```

**å…³é”®æ”¹è¿›**ï¼š
- **é®æŒ¡é¢„æµ‹**ï¼šè¯†åˆ«ç›®æ ‡ç‰©ä½“æ˜¯å¦åœ¨å½“å‰å¸§å¯è§
- **å¤šæ©ç è¾“å‡º**ï¼šå¤„ç†è·¨å¸§æ­§ä¹‰ï¼ˆå¦‚éƒ¨ä»¶vsæ•´ä½“ï¼‰
- **é«˜åˆ†è¾¨ç‡è·³è·ƒ**ï¼šç›´æ¥ä»å›¾åƒç¼–ç å™¨å¼•å…¥ç»†èŠ‚ç‰¹å¾

---

## ğŸ”„ è®­ç»ƒç­–ç•¥è¯¦è§£

### 1. é¢„è®­ç»ƒé˜¶æ®µ (SA-1B)

```python
def pre_training_pipeline():
    # åˆå§‹åŒ–: MAEé¢„è®­ç»ƒçš„Hiera
    model = SAM2(image_encoder='hiera_mae_pretrained')
    
    # æ•°æ®: SA-1Bæ•°æ®é›†
    dataset = SA1BDataset()
    
    # è®­ç»ƒé…ç½®:
    optimizer = AdamW(lr=4e-4, weight_decay=0.1)
    scheduler = ReciprocalSqrtSchedule(timescale=1000)
    
    # æŸå¤±å‡½æ•°:
    losses = {
        'mask': LinearCombination([FocalLoss(20), DiceLoss(1)]),
        'iou': L1Loss(1),  # æ›´æ¿€è¿›çš„IoUç›‘ç£
        'occlusion': CrossEntropyLoss(1)
    }
```

### 2. è”åˆè®­ç»ƒé˜¶æ®µ

```python
def joint_training():
    # æ•°æ®æ··åˆç­–ç•¥
    data_mix = {
        'SA-1B': 15.2%,      # å›¾åƒæ•°æ®
        'SA-V': 70.0%,       # è§†é¢‘æ•°æ®
        'Internal': 14.8%    # å†…éƒ¨è§†é¢‘æ•°æ®
    }
    
    # äº¤æ›¿è®­ç»ƒç­–ç•¥
    for iteration in total_iterations:
        if random() < image_prob:
            batch = sample_image_batch()  # å•å¸§è®­ç»ƒ
            loss = image_task_loss(batch)
        else:
            batch = sample_video_batch()  # 8å¸§åºåˆ—
            loss = video_task_loss(batch)
```

### 3. è§†é¢‘è®­ç»ƒæ¨¡æ‹Ÿ

```python
def simulate_interactive_training(video_sequence, gt_masklet):
    """æ¨¡æ‹Ÿäº¤äº’å¼è®­ç»ƒè¿‡ç¨‹"""
    
    # é‡‡æ ·8å¸§åºåˆ—
    frames = sample_8_frames(video_sequence)
    
    # éšæœºé€‰æ‹©æœ€å¤š2ä¸ªæç¤ºå¸§
    prompt_frames = random.sample(range(8), k=min(2, 8))
    
    predictions = []
    memory_bank = MemoryBank()
    
    for t in range(8):
        # å½“å‰å¸§å¤„ç†
        current_frame = frames[t]
        
        if t in prompt_frames:
            # æ¨¡æ‹Ÿç”¨æˆ·æç¤º (50%æ©ç , 25%ç‚¹å‡», 25%æ¡†)
            prompt_type = sample_prompt_type()
            prompt = generate_prompt(gt_masklet[t], prompt_type)
        else:
            prompt = None
            
        # æ¨¡å‹é¢„æµ‹ï¼ˆä½¿ç”¨è®°å¿†ï¼‰
        mask_pred, occlusion = model(
            current_frame, prompt, memory_bank
        )
        
        # æ›´æ–°è®°å¿†åº“
        memory_bank.add_memory(
            model.image_encoder(current_frame), 
            mask_pred, 
            is_prompted=(t in prompt_frames)
        )
        
        predictions.append(mask_pred)
    
    return compute_loss(predictions, gt_masklet)
```

**æ•°æ®å¢å¼ºç­–ç•¥**ï¼š
- **Mosaicå¢å¼º**ï¼š2Ã—2æ‹¼æ¥ç›¸åŒè§†é¢‘ï¼Œæ¨¡æ‹Ÿç›¸ä¼¼ç‰©ä½“åœºæ™¯
- **æ—¶åºåè½¬**ï¼š50%æ¦‚ç‡åå‘å¤„ç†åºåˆ—
- **é¢œè‰²æŠ–åŠ¨**ï¼šæ¯å¸§ç‹¬ç«‹é¢œè‰²å˜æ¢
- **ä»¿å°„å˜æ¢**ï¼šæ—‹è½¬ã€å‰ªåˆ‡ç­‰ç©ºé—´å˜æ¢

---

## ğŸª æ¨ç†æµç¨‹è¯¦è§£

### æµå¼å¤„ç†ç®—æ³•

```python
class StreamingInference:
    def __init__(self, model):
        self.model = model
        self.memory_bank = MemoryBank()
        self.current_object_pointers = []
        
    def process_frame(self, frame, prompts=None):
        """å¤„ç†å•å¸§"""
        
        # 1. æå–å›¾åƒç‰¹å¾ï¼ˆåªè¿è¡Œä¸€æ¬¡ï¼‰
        frame_emb = self.model.image_encoder(frame)
        
        # 2. è®°å¿†æ³¨æ„åŠ›æ¡ä»¶åŒ–
        conditioned_emb = self.model.memory_attention(
            frame_emb, self.memory_bank
        )
        
        # 3. æ©ç è§£ç ï¼ˆå¯é€‰æç¤ºï¼‰
        masks, occlusion, obj_ptr = self.model.mask_decoder(
            conditioned_emb, prompts, frame_emb
        )
        
        # 4. å¤„ç†å¤šæ©ç æ­§ä¹‰
        if prompts is None and len(masks) > 1:
            # æ— æ–°æç¤ºæ—¶é€‰æ‹©æœ€é«˜IoUæ©ç 
            selected_mask = select_mask_by_iou(masks)
        else:
            selected_mask = masks[0]  # æç¤ºå·²è§£å†³æ­§ä¹‰
            
        # 5. æ›´æ–°è®°å¿†
        self.memory_bank.add_memory(
            frame_emb, selected_mask, 
            is_prompted=(prompts is not None)
        )
        
        return selected_mask, occlusion
```

### å¤šç‰©ä½“å¤„ç†

```python
def process_multiple_objects(video_frames, object_prompts):
    """å¤„ç†è§†é¢‘ä¸­çš„å¤šä¸ªç‰©ä½“"""
    
    # å…±äº«å›¾åƒç¼–ç ï¼ˆè®¡ç®—æ•ˆç‡ï¼‰
    frame_embeddings = [
        model.image_encoder(frame) for frame in video_frames
    ]
    
    results = {}
    for obj_id, prompts in object_prompts.items():
        # æ¯ä¸ªç‰©ä½“ç‹¬ç«‹çš„å†…å­˜åº“å’Œå¤„ç†å™¨
        obj_processor = StreamingInference(model)
        obj_masks = []
        
        for t, frame_emb in enumerate(frame_embeddings):
            frame_prompts = prompts.get(t, None)
            mask, _ = obj_processor.process_frame(
                frame_emb, frame_prompts
            )
            obj_masks.append(mask)
            
        results[obj_id] = obj_masks
    
    return results
```

---

## âš¡ å…³é”®æŠ€æœ¯åˆ›æ–°

### 1. è®°å¿†æœºåˆ¶è®¾è®¡

**ç©ºé—´è®°å¿†**ï¼š
- å­˜å‚¨æœ€è¿‘Nå¸§çš„ç‰¹å¾å›¾
- ä½¿ç”¨2D-RoPEä½ç½®ç¼–ç æ•æ‰çŸ­æœŸè¿åŠ¨
- é€šé“ç»´åº¦å‹ç¼©ï¼ˆ64ç»´ï¼‰å‡å°‘å†…å­˜å ç”¨

**ç‰©ä½“æŒ‡é’ˆ**ï¼š
- ä»æ©ç è§£ç å™¨è¾“å‡ºtokenæå–
- ç¼–ç é«˜çº§è¯­ä¹‰ä¿¡æ¯
- å¢å¼ºé•¿æ—¶åºä¸€è‡´æ€§

### 2. é«˜æ•ˆæ³¨æ„åŠ›ä¼˜åŒ–

```python
# ä½¿ç”¨FlashAttention-2åŠ é€Ÿ
def optimized_attention():
    # ç§»é™¤RPBï¼Œå¯ç”¨FlashAttention
    with torch.backends.cuda.sdp_kernel():
        attn_output = F.scaled_dot_product_attention(
            q, k, v, attn_mask=None
        )
```

### 3. æ­§ä¹‰å¤„ç†ç­–ç•¥

```python
def handle_temporal_ambiguity(masks, prev_masks, prompts):
    """å¤„ç†è·¨å¸§åˆ†å‰²æ­§ä¹‰"""
    
    if prompts:  # æœ‰æ–°æç¤ºï¼Œè§£å†³æ­§ä¹‰
        return resolve_ambiguity_with_prompts(masks, prompts)
    elif prev_masks:  # ä¼ æ’­å…ˆå‰é€‰æ‹©
        return propagate_previous_selection(masks, prev_masks)
    else:  # é€‰æ‹©å½“å‰æœ€ä½³
        return select_by_iou(masks)
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–åˆ†æ

### é€Ÿåº¦ä¼˜åŠ¿æ¥æº

1. **é«˜æ•ˆå›¾åƒç¼–ç å™¨**ï¼šHieraæ¯”ViTæ›´å¿«ä¸”æ€§èƒ½ç›¸å½“
2. **è®°å¿†é€šé“å‹ç¼©**ï¼š64ç»´vs 256ç»´ï¼Œ4å€å†…å­˜èŠ‚çœ
3. **æ³¨æ„åŠ›ä¼˜åŒ–**ï¼šç§»é™¤RPBï¼Œå¯ç”¨FlashAttention-2
4. **æµå¼å¤„ç†**ï¼šé¿å…é‡å¤ç¼–ç ï¼Œæ”¯æŒå®æ—¶åº”ç”¨

### ç²¾åº¦æå‡å› ç´ 

1. **æ—¶åºä¸€è‡´æ€§**ï¼šè®°å¿†æœºåˆ¶ä¿æŒè·¨å¸§ç¨³å®šæ€§
2. **é«˜åˆ†è¾¨ç‡ç»†èŠ‚**ï¼šè·³è·ƒè¿æ¥ä¿ç•™ç©ºé—´ç»†èŠ‚
3. **å¤šæ ·åŒ–è®­ç»ƒ**ï¼šSA-Væ•°æ®é›†è¦†ç›–å„ç§æŒ‘æˆ˜åœºæ™¯
4. **äº¤äº’å¼ä¼˜åŒ–**ï¼šæ¨¡æ‹Ÿè®­ç»ƒåŒ¹é…çœŸå®ä½¿ç”¨æ¨¡å¼

---

## ğŸ”® æ€»ç»“

SAM 2é€šè¿‡**è®°å¿†å¢å¼ºçš„æµå¼æ¶æ„**ã€**ç»Ÿä¸€çš„ä»»åŠ¡å®šä¹‰**å’Œ**å¤§è§„æ¨¡å¤šæ ·åŒ–æ•°æ®é›†**ï¼ŒæˆåŠŸå°†SAMçš„èƒ½åŠ›æ‰©å±•åˆ°è§†é¢‘é¢†åŸŸã€‚å…¶æ ¸å¿ƒç®—æ³•åˆ›æ–°åŒ…æ‹¬ï¼š

- **è®°å¿†æ³¨æ„åŠ›æœºåˆ¶**å®ç°æ—¶åºå»ºæ¨¡
- **ç‰©ä½“æŒ‡é’ˆå‘é‡**å¢å¼ºè¯­ä¹‰ä¸€è‡´æ€§  
- **å¤šæ©ç æ­§ä¹‰å¤„ç†**åº”å¯¹å¤æ‚åœºæ™¯
- **é«˜æ•ˆæµå¼æ¨ç†**æ”¯æŒå®æ—¶åº”ç”¨

è¿™å¥—ç®—æ³•æ¡†æ¶ä¸ºè§†é¢‘åˆ†å‰²å»ºç«‹äº†æ–°çš„æŠ€æœ¯æ ‡å‡†ï¼Œå¹¶ä¸ºæœªæ¥çš„è§†é¢‘ç†è§£ç ”ç©¶æä¾›äº†é‡è¦åŸºç¡€ã€‚
